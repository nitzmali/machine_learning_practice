{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)\n",
    "import keras\n",
    "import warnings # to filter out warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data from keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data() \n",
    "\n",
    "X_train = X_train.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
    "X_test = X_test.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
    "\n",
    "#X_train= X_train.reshape(X_train.shape[0],X_train.shape[1]*X_train.shape[2])\n",
    "#X_test = X_test.reshape(X_test.shape[0],X_test.shape[1]*X_test.shape[2])\n",
    "#y_train = y_train.reshape(y_train.shape[0],1)\n",
    "#y_test = y_test.reshape(y_test.shape[0],1)\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 a) CNN model from scratch: Develop a CNN model with 5 convolutional layers (with kernel size= 3, stride =1, padding = “same”, activation function = “relu”) with following MaxPooling layer (Size= 2) and 3 fully connected layer (including one output layer). After each of the Convolutional layer apply Batch Normalization. In the fully connected layer apply dropout (rate 0.50). Show the learning curve. Report performance evaluation on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 319s 169ms/step - loss: 1.2642 - accuracy: 0.5476 - val_loss: 0.6456 - val_accuracy: 0.7517\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 316s 169ms/step - loss: 0.8358 - accuracy: 0.6702 - val_loss: 0.6191 - val_accuracy: 0.7441\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 316s 169ms/step - loss: 0.7370 - accuracy: 0.7032 - val_loss: 0.5558 - val_accuracy: 0.7693\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 326s 174ms/step - loss: 0.6367 - accuracy: 0.7369 - val_loss: 0.5222 - val_accuracy: 0.7754\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 337s 180ms/step - loss: 0.5637 - accuracy: 0.7606 - val_loss: 0.4622 - val_accuracy: 0.8053\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 340s 181ms/step - loss: 0.5266 - accuracy: 0.7790 - val_loss: 0.4743 - val_accuracy: 0.8046\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 332s 177ms/step - loss: 0.4894 - accuracy: 0.8094 - val_loss: 0.3896 - val_accuracy: 0.8737\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 327s 175ms/step - loss: 0.4124 - accuracy: 0.8540 - val_loss: 0.3201 - val_accuracy: 0.8975\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 316s 169ms/step - loss: 0.3706 - accuracy: 0.8704 - val_loss: 0.3102 - val_accuracy: 0.8978\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 323s 172ms/step - loss: 0.3427 - accuracy: 0.8811 - val_loss: 0.2723 - val_accuracy: 0.9126\n",
      "313/313 [==============================] - 13s 42ms/step - loss: 0.2723 - accuracy: 0.9126\n",
      "\n",
      "Test Accuracy: 91.26%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models,layers\n",
    "#from tensorflow.keras.models import Sequential \n",
    "#from tensorflow.keras.models import Dense \n",
    "#from tensorflow.keras import regularizers\n",
    "tf.random.set_seed(1234)\n",
    "def create_model():\n",
    "    # Building the CNN model\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), strides=(1, 1), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "\n",
    "    for _ in range(4):\n",
    "        model.add(layers.Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(10, activation='softmax'))  # Output layer\n",
    "\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model()\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32,\n",
    "                    validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the test accuracy\n",
    "print(f\"\\nTest Accuracy: {test_acc * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_342 (Conv2D)         (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization_342 (Ba  (None, 28, 28, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_343 (Conv2D)         (None, 28, 28, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_343 (Ba  (None, 28, 28, 64)       256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_344 (Conv2D)         (None, 28, 28, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_344 (Ba  (None, 28, 28, 64)       256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_345 (Conv2D)         (None, 28, 28, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_345 (Ba  (None, 28, 28, 64)       256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_346 (Conv2D)         (None, 28, 28, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_346 (Ba  (None, 28, 28, 64)       256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_81 (MaxPoolin  (None, 14, 14, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_51 (Flatten)        (None, 12544)             0         \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 128)               1605760   \n",
      "                                                                 \n",
      " dropout_105 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_166 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_106 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,745,418\n",
      "Trainable params: 1,744,842\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1b) Apply 5-Fold Cross Validation on the CNN model developed in a and report the average accuracy with standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 284s 188ms/step - loss: 1.3177 - accuracy: 0.5443\n",
      "375/375 [==============================] - 20s 52ms/step - loss: 0.6934 - accuracy: 0.7433\n",
      "1500/1500 [==============================] - 280s 185ms/step - loss: 1.3918 - accuracy: 0.5078\n",
      "375/375 [==============================] - 15s 40ms/step - loss: 0.7021 - accuracy: 0.7485\n",
      "1500/1500 [==============================] - 246s 162ms/step - loss: 1.3172 - accuracy: 0.5393\n",
      "375/375 [==============================] - 13s 35ms/step - loss: 0.7211 - accuracy: 0.7406\n",
      "1500/1500 [==============================] - 242s 160ms/step - loss: 1.2602 - accuracy: 0.5717\n",
      "375/375 [==============================] - 14s 38ms/step - loss: 0.6341 - accuracy: 0.7473\n",
      "1500/1500 [==============================] - 244s 161ms/step - loss: 1.3920 - accuracy: 0.4937\n",
      "375/375 [==============================] - 15s 39ms/step - loss: 0.8227 - accuracy: 0.6572\n",
      "Baseline Accuracy: 72.74% (+/- 3.52%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "# Wrap Keras model into scikit-learn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=1, batch_size=32, verbose=1)\n",
    "\n",
    "# 5-Fold Cross validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "\n",
    "results = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(f\"Baseline Accuracy: {results.mean()*100:.2f}% (+/- {results.std()*100:.2f}%)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 c) Apply grid search on the CNN model to find the optimal set of hyperparameters that produce the max performance on the test data. You must train the model using the training data and evaluate model performance using the test dataset. Use grid search for hyperparameter tuning with the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Act: relu, Opt: adam, Batch: 16, LR: 0.001, Test Acc: 87.90%\n",
      "Act: relu, Opt: adam, Batch: 16, LR: 0.0001, Test Acc: 87.10%\n",
      "Act: relu, Opt: adam, Batch: 16, LR: 1e-05, Test Acc: 84.54%\n",
      "Act: relu, Opt: adam, Batch: 32, LR: 0.001, Test Acc: 86.19%\n",
      "Act: relu, Opt: adam, Batch: 32, LR: 0.0001, Test Acc: 85.66%\n",
      "Act: relu, Opt: adam, Batch: 32, LR: 1e-05, Test Acc: 81.77%\n",
      "Act: relu, Opt: adam, Batch: 64, LR: 0.001, Test Acc: 87.04%\n",
      "Act: relu, Opt: adam, Batch: 64, LR: 0.0001, Test Acc: 86.30%\n",
      "Act: relu, Opt: adam, Batch: 64, LR: 1e-05, Test Acc: 81.82%\n",
      "Act: relu, Opt: adagrad, Batch: 16, LR: 0.001, Test Acc: 86.49%\n",
      "Act: relu, Opt: adagrad, Batch: 16, LR: 0.0001, Test Acc: 79.53%\n",
      "Act: relu, Opt: adagrad, Batch: 16, LR: 1e-05, Test Acc: 53.61%\n",
      "Act: relu, Opt: adagrad, Batch: 32, LR: 0.001, Test Acc: 85.84%\n",
      "Act: relu, Opt: adagrad, Batch: 32, LR: 0.0001, Test Acc: 79.23%\n",
      "Act: relu, Opt: adagrad, Batch: 32, LR: 1e-05, Test Acc: 56.35%\n",
      "Act: relu, Opt: adagrad, Batch: 64, LR: 0.001, Test Acc: 85.71%\n",
      "Act: relu, Opt: adagrad, Batch: 64, LR: 0.0001, Test Acc: 78.88%\n",
      "Act: relu, Opt: adagrad, Batch: 64, LR: 1e-05, Test Acc: 50.98%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adam, Batch: 16, LR: 0.001, Test Acc: 87.22%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adam, Batch: 16, LR: 0.0001, Test Acc: 86.52%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adam, Batch: 16, LR: 1e-05, Test Acc: 85.15%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adam, Batch: 32, LR: 0.001, Test Acc: 86.83%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adam, Batch: 32, LR: 0.0001, Test Acc: 86.69%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adam, Batch: 32, LR: 1e-05, Test Acc: 83.98%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adam, Batch: 64, LR: 0.001, Test Acc: 85.66%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adam, Batch: 64, LR: 0.0001, Test Acc: 86.92%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adam, Batch: 64, LR: 1e-05, Test Acc: 82.61%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adagrad, Batch: 16, LR: 0.001, Test Acc: 86.75%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adagrad, Batch: 16, LR: 0.0001, Test Acc: 81.08%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adagrad, Batch: 16, LR: 1e-05, Test Acc: 61.45%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adagrad, Batch: 32, LR: 0.001, Test Acc: 85.40%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adagrad, Batch: 32, LR: 0.0001, Test Acc: 80.58%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adagrad, Batch: 32, LR: 1e-05, Test Acc: 63.04%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adagrad, Batch: 64, LR: 0.001, Test Acc: 85.74%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adagrad, Batch: 64, LR: 0.0001, Test Acc: 78.80%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adagrad, Batch: 64, LR: 1e-05, Test Acc: 59.20%\n",
      "\n",
      "Best Parameters - Act: relu, Opt: adam, Batch: 16, LR: 0.001, Test Acc: 87.90%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam, Adagrad\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "import itertools\n",
    "\n",
    "# Define the grid search parameters\n",
    "activation_functions = ['relu', LeakyReLU()] \n",
    "optimizers = ['adam', 'adagrad']  \n",
    "batch_sizes = [16, 32, 64]  \n",
    "learning_rates = [0.001, 0.0001, 0.00001] \n",
    "\n",
    "# Placeholder to store the results\n",
    "grid_search_results = []\n",
    "\n",
    "# Loop through the parameter combinations\n",
    "for params in itertools.product(activation_functions, optimizers, batch_sizes, learning_rates):\n",
    "    act_func, opt, batch, lr = params\n",
    "    \n",
    "    # Creating the model\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), padding='same', input_shape=(28, 28, 1)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    if act_func == 'relu':\n",
    "        model.add(layers.Activation('relu'))\n",
    "    else:\n",
    "        model.add(LeakyReLU())\n",
    "    \n",
    "    for _ in range(4):\n",
    "        model.add(layers.Conv2D(64, (3, 3), padding='same'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        if act_func == 'relu':\n",
    "            model.add(layers.Activation('relu'))\n",
    "        else:\n",
    "            model.add(LeakyReLU())\n",
    "        \n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(64))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(10, activation='softmax'))  # Output layer\n",
    "\n",
    "    if opt == 'adam':\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "    else:\n",
    "        optimizer = Adagrad(learning_rate=lr)\n",
    "        \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=1, batch_size=batch, verbose=0)  \n",
    "\n",
    "    # Evaluate the model\n",
    "    _, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    grid_search_results.append((act_func, opt, batch, lr, test_acc))\n",
    "    print(f\"Act: {act_func}, Opt: {opt}, Batch: {batch}, LR: {lr}, Test Acc: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Print the best result\n",
    "best_params = max(grid_search_results, key=lambda x: x[4])\n",
    "print(f\"\\nBest Parameters - Act: {best_params[0]}, Opt: {best_params[1]}, Batch: {best_params[2]}, LR: {best_params[3]}, Test Acc: {best_params[4]*100:.2f}%\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 d) Data Augmentation: Apply five different image augmentation techniques on the Fashion Mnist train data to augment it and then apply the previously designed (from a) model on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 128s 67ms/step - loss: 1.1889 - accuracy: 0.5749 - val_loss: 0.6493 - val_accuracy: 0.7516\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 125s 67ms/step - loss: 0.7731 - accuracy: 0.6980 - val_loss: 0.5727 - val_accuracy: 0.7626\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 125s 67ms/step - loss: 0.6961 - accuracy: 0.7203 - val_loss: 0.5972 - val_accuracy: 0.7404\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 131s 70ms/step - loss: 0.6321 - accuracy: 0.7394 - val_loss: 0.5239 - val_accuracy: 0.7836\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 126s 67ms/step - loss: 0.5903 - accuracy: 0.7659 - val_loss: 0.4636 - val_accuracy: 0.8416\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 125s 67ms/step - loss: 0.5540 - accuracy: 0.7856 - val_loss: 0.4406 - val_accuracy: 0.8499\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 128s 68ms/step - loss: 0.5227 - accuracy: 0.8015 - val_loss: 0.3911 - val_accuracy: 0.8547\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 128s 68ms/step - loss: 0.5003 - accuracy: 0.8118 - val_loss: 0.3829 - val_accuracy: 0.8596\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 127s 68ms/step - loss: 0.4663 - accuracy: 0.8291 - val_loss: 0.3591 - val_accuracy: 0.8831\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 125s 66ms/step - loss: 0.4419 - accuracy: 0.8416 - val_loss: 0.3272 - val_accuracy: 0.8820\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.3272 - accuracy: 0.8820\n",
      "\n",
      "Test Accuracy after Data Augmentation: 88.20%\n"
     ]
    }
   ],
   "source": [
    "#Data Augumentation \n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create an instance of the ImageDataGenerator class\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,       # Rotate images up to 10 degrees\n",
    "    width_shift_range=0.1,   # Shift images horizontally\n",
    "    height_shift_range=0.1,  # Shift images vertically\n",
    "    shear_range=0.1,         # Shear transformation\n",
    "    zoom_range=0.1           # Zoom in on images\n",
    ")\n",
    "\n",
    "# Fit the data generator to your training data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Rebuilding your model from part (a)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), strides=(1, 1), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "for _ in range(4):\n",
    "    model.add(layers.Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='softmax'))  # Output layer\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training the model using the augmented data generator\n",
    "# Note that steps_per_epoch should usually be total_samples / batch_size\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
    "                    steps_per_epoch=len(X_train) / 32, epochs=10,\n",
    "                    validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate and print test accuracy\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nTest Accuracy after Data Augmentation: {test_acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_61\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_372 (Conv2D)         (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization_372 (Ba  (None, 28, 28, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_87 (MaxPoolin  (None, 14, 14, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_373 (Conv2D)         (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_373 (Ba  (None, 14, 14, 64)       256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_374 (Conv2D)         (None, 14, 14, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_374 (Ba  (None, 14, 14, 64)       256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_375 (Conv2D)         (None, 14, 14, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_375 (Ba  (None, 14, 14, 64)       256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_376 (Conv2D)         (None, 14, 14, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_376 (Ba  (None, 14, 14, 64)       256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " flatten_57 (Flatten)        (None, 12544)             0         \n",
      "                                                                 \n",
      " dense_183 (Dense)           (None, 128)               1605760   \n",
      "                                                                 \n",
      " dropout_117 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_184 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_118 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " dense_185 (Dense)           (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,745,418\n",
      "Trainable params: 1,744,842\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 e) Transfer Learning: Load the VGG-19 model. Drop after the block4 conv1 layer (highlighted in the image below) and on top of it add one global average pooling layer, one fully connected layer, and one final output layer. Keep the base model layers (VGG19) freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " global_average_pooling2d_8   (None, 512)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_148 (Dense)           (None, 128)               65664     \n",
      "                                                                 \n",
      " dropout_94 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,572,682\n",
      "Trainable params: 66,954\n",
      "Non-trainable params: 3,505,728\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "\n",
    "# Load the VGG19 model\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Truncate the model at 'block4_conv1'\n",
    "base_output = base_model.get_layer('block4_conv1').output\n",
    "\n",
    "# Add new layers on top\n",
    "x = GlobalAveragePooling2D()(base_output)  # Global Average Pooling layer\n",
    "x = Dense(128, activation='relu')(x)  # Fully connected layer with 128 neurons\n",
    "x = Dropout(0.5)(x)  # Dropout layer for regularization\n",
    "predictions = Dense(10, activation='softmax')(x)  # Output layer assuming 10 classes\n",
    "\n",
    "# Assemble the final model\n",
    "final_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze all layers in the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Print the model summary to check the architecture\n",
    "final_model.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Dveloping ResNet model from scratch\n",
    "Apply a residual network specified in the following architecture. All convolutional layers use kernel size 3, stride = 1, and padding = “same”,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_16 (InputLayer)          [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_440 (Conv2D)            (None, 28, 28, 32)   320         ['input_16[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_440 (Batch  (None, 28, 28, 32)  128         ['conv2d_440[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_119 (ReLU)               (None, 28, 28, 32)   0           ['batch_normalization_440[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_441 (Conv2D)            (None, 28, 28, 32)   9248        ['re_lu_119[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_441 (Batch  (None, 28, 28, 32)  128         ['conv2d_441[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_120 (ReLU)               (None, 28, 28, 32)   0           ['batch_normalization_441[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_442 (Conv2D)            (None, 28, 28, 32)   9248        ['re_lu_120[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_442 (Batch  (None, 28, 28, 32)  128         ['conv2d_442[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_57 (Add)                   (None, 28, 28, 32)   0           ['batch_normalization_442[0][0]',\n",
      "                                                                  're_lu_119[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_121 (ReLU)               (None, 28, 28, 32)   0           ['add_57[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_443 (Conv2D)            (None, 28, 28, 32)   9248        ['re_lu_121[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_443 (Batch  (None, 28, 28, 32)  128         ['conv2d_443[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_122 (ReLU)               (None, 28, 28, 32)   0           ['batch_normalization_443[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_444 (Conv2D)            (None, 28, 28, 32)   9248        ['re_lu_122[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_444 (Batch  (None, 28, 28, 32)  128         ['conv2d_444[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_58 (Add)                   (None, 28, 28, 32)   0           ['batch_normalization_444[0][0]',\n",
      "                                                                  're_lu_121[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_123 (ReLU)               (None, 28, 28, 32)   0           ['add_58[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_445 (Conv2D)            (None, 28, 28, 32)   9248        ['re_lu_123[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_445 (Batch  (None, 28, 28, 32)  128         ['conv2d_445[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_124 (ReLU)               (None, 28, 28, 32)   0           ['batch_normalization_445[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_446 (Conv2D)            (None, 28, 28, 32)   9248        ['re_lu_124[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_446 (Batch  (None, 28, 28, 32)  128         ['conv2d_446[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_59 (Add)                   (None, 28, 28, 32)   0           ['batch_normalization_446[0][0]',\n",
      "                                                                  're_lu_123[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_125 (ReLU)               (None, 28, 28, 32)   0           ['add_59[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_447 (Conv2D)            (None, 28, 28, 64)   18496       ['re_lu_125[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_447 (Batch  (None, 28, 28, 64)  256         ['conv2d_447[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_126 (ReLU)               (None, 28, 28, 64)   0           ['batch_normalization_447[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_448 (Conv2D)            (None, 28, 28, 64)   36928       ['re_lu_126[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_449 (Conv2D)            (None, 28, 28, 64)   2112        ['re_lu_125[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_448 (Batch  (None, 28, 28, 64)  256         ['conv2d_448[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_449 (Batch  (None, 28, 28, 64)  256         ['conv2d_449[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_60 (Add)                   (None, 28, 28, 64)   0           ['batch_normalization_448[0][0]',\n",
      "                                                                  'batch_normalization_449[0][0]']\n",
      "                                                                                                  \n",
      " re_lu_127 (ReLU)               (None, 28, 28, 64)   0           ['add_60[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_450 (Conv2D)            (None, 28, 28, 64)   36928       ['re_lu_127[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_450 (Batch  (None, 28, 28, 64)  256         ['conv2d_450[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_128 (ReLU)               (None, 28, 28, 64)   0           ['batch_normalization_450[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_451 (Conv2D)            (None, 28, 28, 64)   36928       ['re_lu_128[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_451 (Batch  (None, 28, 28, 64)  256         ['conv2d_451[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_61 (Add)                   (None, 28, 28, 64)   0           ['batch_normalization_451[0][0]',\n",
      "                                                                  're_lu_127[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_129 (ReLU)               (None, 28, 28, 64)   0           ['add_61[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_452 (Conv2D)            (None, 28, 28, 64)   36928       ['re_lu_129[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_452 (Batch  (None, 28, 28, 64)  256         ['conv2d_452[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_130 (ReLU)               (None, 28, 28, 64)   0           ['batch_normalization_452[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_453 (Conv2D)            (None, 28, 28, 64)   36928       ['re_lu_130[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_453 (Batch  (None, 28, 28, 64)  256         ['conv2d_453[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_62 (Add)                   (None, 28, 28, 64)   0           ['batch_normalization_453[0][0]',\n",
      "                                                                  're_lu_129[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_131 (ReLU)               (None, 28, 28, 64)   0           ['add_62[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_454 (Conv2D)            (None, 28, 28, 128)  73856       ['re_lu_131[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_454 (Batch  (None, 28, 28, 128)  512        ['conv2d_454[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_132 (ReLU)               (None, 28, 28, 128)  0           ['batch_normalization_454[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_455 (Conv2D)            (None, 28, 28, 128)  147584      ['re_lu_132[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_456 (Conv2D)            (None, 28, 28, 128)  8320        ['re_lu_131[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_455 (Batch  (None, 28, 28, 128)  512        ['conv2d_455[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_456 (Batch  (None, 28, 28, 128)  512        ['conv2d_456[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_63 (Add)                   (None, 28, 28, 128)  0           ['batch_normalization_455[0][0]',\n",
      "                                                                  'batch_normalization_456[0][0]']\n",
      "                                                                                                  \n",
      " re_lu_133 (ReLU)               (None, 28, 28, 128)  0           ['add_63[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_457 (Conv2D)            (None, 28, 28, 128)  147584      ['re_lu_133[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_457 (Batch  (None, 28, 28, 128)  512        ['conv2d_457[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_134 (ReLU)               (None, 28, 28, 128)  0           ['batch_normalization_457[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_458 (Conv2D)            (None, 28, 28, 128)  147584      ['re_lu_134[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_458 (Batch  (None, 28, 28, 128)  512        ['conv2d_458[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_64 (Add)                   (None, 28, 28, 128)  0           ['batch_normalization_458[0][0]',\n",
      "                                                                  're_lu_133[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_135 (ReLU)               (None, 28, 28, 128)  0           ['add_64[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_459 (Conv2D)            (None, 28, 28, 128)  147584      ['re_lu_135[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_459 (Batch  (None, 28, 28, 128)  512        ['conv2d_459[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_136 (ReLU)               (None, 28, 28, 128)  0           ['batch_normalization_459[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_460 (Conv2D)            (None, 28, 28, 128)  147584      ['re_lu_136[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_460 (Batch  (None, 28, 28, 128)  512        ['conv2d_460[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_65 (Add)                   (None, 28, 28, 128)  0           ['batch_normalization_460[0][0]',\n",
      "                                                                  're_lu_135[0][0]']              \n",
      "                                                                                                  \n",
      " re_lu_137 (ReLU)               (None, 28, 28, 128)  0           ['add_65[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_12 (G  (None, 128)         0           ['re_lu_137[0][0]']              \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " flatten_61 (Flatten)           (None, 128)          0           ['global_average_pooling2d_12[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_192 (Dense)              (None, 128)          16512       ['flatten_61[0][0]']             \n",
      "                                                                                                  \n",
      " dense_193 (Dense)              (None, 10)           1290        ['dense_192[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,105,226\n",
      "Trainable params: 1,102,090\n",
      "Non-trainable params: 3,136\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, Add, GlobalAveragePooling2D, Dense, Flatten\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "\n",
    "# Function to create a residual block\n",
    "def residual_block(x, filters):\n",
    "    shortcut = x\n",
    "    \n",
    "    # Main path\n",
    "    x = Conv2D(filters, (3,3), strides=(1,1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(filters, (3,3), strides=(1,1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # If the number of filters does not match, apply a 1x1 conv to the shortcut path\n",
    "    if shortcut.shape[-1] != filters:\n",
    "        shortcut = Conv2D(filters, (1,1), strides=(1,1), padding='same')(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)  # Optional: add BatchNormalization here as well\n",
    "    \n",
    "    # Adding the shortcut to the output\n",
    "    x = Add()([x, shortcut])\n",
    "    x = ReLU()(x)\n",
    "    return x\n",
    "\n",
    "# Function to create the ResNet model\n",
    "def create_resnet_model():\n",
    "    inputs = Input(shape=(28, 28, 1))  # Adjust the input shape according to your data\n",
    "    x = Conv2D(32, (3,3), strides=(1,1), padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    # Section A\n",
    "    for _ in range(3):\n",
    "        x = residual_block(x, 32)\n",
    "    \n",
    "    # Section B\n",
    "    for _ in range(3):\n",
    "        x = residual_block(x, 64)\n",
    "    \n",
    "    # Section C\n",
    "    for _ in range(3):\n",
    "        x = residual_block(x, 128)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)  # Adjust the size and activation function according to your needs\n",
    "    outputs = Dense(10, activation='softmax')(x)  # Assuming 10 classes for classification\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_resnet_model()\n",
    "# Print model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_296 (Conv2D)            (None, 28, 28, 32)   320         ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_296 (Batch  (None, 28, 28, 32)  128         ['conv2d_296[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_43 (ReLU)                (None, 28, 28, 32)   0           ['batch_normalization_296[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_297 (Conv2D)            (None, 28, 28, 32)   9248        ['re_lu_43[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_297 (Batch  (None, 28, 28, 32)  128         ['conv2d_297[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_44 (ReLU)                (None, 28, 28, 32)   0           ['batch_normalization_297[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_298 (Conv2D)            (None, 28, 28, 32)   9248        ['re_lu_44[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_298 (Batch  (None, 28, 28, 32)  128         ['conv2d_298[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 28, 28, 32)   0           ['batch_normalization_298[0][0]',\n",
      "                                                                  're_lu_43[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_45 (ReLU)                (None, 28, 28, 32)   0           ['add_21[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_299 (Conv2D)            (None, 28, 28, 32)   9248        ['re_lu_45[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_299 (Batch  (None, 28, 28, 32)  128         ['conv2d_299[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_46 (ReLU)                (None, 28, 28, 32)   0           ['batch_normalization_299[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_300 (Conv2D)            (None, 28, 28, 32)   9248        ['re_lu_46[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_300 (Batch  (None, 28, 28, 32)  128         ['conv2d_300[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_22 (Add)                   (None, 28, 28, 32)   0           ['batch_normalization_300[0][0]',\n",
      "                                                                  're_lu_45[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_47 (ReLU)                (None, 28, 28, 32)   0           ['add_22[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_301 (Conv2D)            (None, 28, 28, 32)   9248        ['re_lu_47[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_301 (Batch  (None, 28, 28, 32)  128         ['conv2d_301[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_48 (ReLU)                (None, 28, 28, 32)   0           ['batch_normalization_301[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_302 (Conv2D)            (None, 28, 28, 32)   9248        ['re_lu_48[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_302 (Batch  (None, 28, 28, 32)  128         ['conv2d_302[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, 28, 28, 32)   0           ['batch_normalization_302[0][0]',\n",
      "                                                                  're_lu_47[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_49 (ReLU)                (None, 28, 28, 32)   0           ['add_23[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_303 (Conv2D)            (None, 28, 28, 64)   18496       ['re_lu_49[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_303 (Batch  (None, 28, 28, 64)  256         ['conv2d_303[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_50 (ReLU)                (None, 28, 28, 64)   0           ['batch_normalization_303[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_304 (Conv2D)            (None, 28, 28, 64)   36928       ['re_lu_50[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_305 (Conv2D)            (None, 28, 28, 64)   2112        ['re_lu_49[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_304 (Batch  (None, 28, 28, 64)  256         ['conv2d_304[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_305 (Batch  (None, 28, 28, 64)  256         ['conv2d_305[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_24 (Add)                   (None, 28, 28, 64)   0           ['batch_normalization_304[0][0]',\n",
      "                                                                  'batch_normalization_305[0][0]']\n",
      "                                                                                                  \n",
      " re_lu_51 (ReLU)                (None, 28, 28, 64)   0           ['add_24[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_306 (Conv2D)            (None, 28, 28, 64)   36928       ['re_lu_51[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_306 (Batch  (None, 28, 28, 64)  256         ['conv2d_306[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_52 (ReLU)                (None, 28, 28, 64)   0           ['batch_normalization_306[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_307 (Conv2D)            (None, 28, 28, 64)   36928       ['re_lu_52[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_307 (Batch  (None, 28, 28, 64)  256         ['conv2d_307[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_25 (Add)                   (None, 28, 28, 64)   0           ['batch_normalization_307[0][0]',\n",
      "                                                                  're_lu_51[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_53 (ReLU)                (None, 28, 28, 64)   0           ['add_25[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_308 (Conv2D)            (None, 28, 28, 64)   36928       ['re_lu_53[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_308 (Batch  (None, 28, 28, 64)  256         ['conv2d_308[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_54 (ReLU)                (None, 28, 28, 64)   0           ['batch_normalization_308[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_309 (Conv2D)            (None, 28, 28, 64)   36928       ['re_lu_54[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_309 (Batch  (None, 28, 28, 64)  256         ['conv2d_309[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_26 (Add)                   (None, 28, 28, 64)   0           ['batch_normalization_309[0][0]',\n",
      "                                                                  're_lu_53[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_55 (ReLU)                (None, 28, 28, 64)   0           ['add_26[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_310 (Conv2D)            (None, 28, 28, 128)  73856       ['re_lu_55[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_310 (Batch  (None, 28, 28, 128)  512        ['conv2d_310[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_56 (ReLU)                (None, 28, 28, 128)  0           ['batch_normalization_310[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_311 (Conv2D)            (None, 28, 28, 128)  147584      ['re_lu_56[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_312 (Conv2D)            (None, 28, 28, 128)  8320        ['re_lu_55[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_311 (Batch  (None, 28, 28, 128)  512        ['conv2d_311[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_312 (Batch  (None, 28, 28, 128)  512        ['conv2d_312[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_27 (Add)                   (None, 28, 28, 128)  0           ['batch_normalization_311[0][0]',\n",
      "                                                                  'batch_normalization_312[0][0]']\n",
      "                                                                                                  \n",
      " re_lu_57 (ReLU)                (None, 28, 28, 128)  0           ['add_27[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_313 (Conv2D)            (None, 28, 28, 128)  147584      ['re_lu_57[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_313 (Batch  (None, 28, 28, 128)  512        ['conv2d_313[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_58 (ReLU)                (None, 28, 28, 128)  0           ['batch_normalization_313[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_314 (Conv2D)            (None, 28, 28, 128)  147584      ['re_lu_58[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_314 (Batch  (None, 28, 28, 128)  512        ['conv2d_314[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_28 (Add)                   (None, 28, 28, 128)  0           ['batch_normalization_314[0][0]',\n",
      "                                                                  're_lu_57[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_59 (ReLU)                (None, 28, 28, 128)  0           ['add_28[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_315 (Conv2D)            (None, 28, 28, 128)  147584      ['re_lu_59[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_315 (Batch  (None, 28, 28, 128)  512        ['conv2d_315[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_60 (ReLU)                (None, 28, 28, 128)  0           ['batch_normalization_315[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_316 (Conv2D)            (None, 28, 28, 128)  147584      ['re_lu_60[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_316 (Batch  (None, 28, 28, 128)  512        ['conv2d_316[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_29 (Add)                   (None, 28, 28, 128)  0           ['batch_normalization_316[0][0]',\n",
      "                                                                  're_lu_59[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_61 (ReLU)                (None, 28, 28, 128)  0           ['add_29[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_5 (Gl  (None, 128)         0           ['re_lu_61[0][0]']               \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " flatten_45 (Flatten)           (None, 128)          0           ['global_average_pooling2d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_142 (Dense)              (None, 128)          16512       ['flatten_45[0][0]']             \n",
      "                                                                                                  \n",
      " dense_143 (Dense)              (None, 10)           1290        ['dense_142[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,105,226\n",
      "Trainable params: 1,102,090\n",
      "Non-trainable params: 3,136\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1875/1875 [==============================] - 1818s 967ms/step - loss: 0.4970 - accuracy: 0.8194 - val_loss: 0.6456 - val_accuracy: 0.7833\n",
      "Epoch 2/2\n",
      "1875/1875 [==============================] - 1612s 859ms/step - loss: 0.3226 - accuracy: 0.8834 - val_loss: 0.4080 - val_accuracy: 0.8667\n",
      "313/313 [==============================] - 73s 233ms/step - loss: 0.4080 - accuracy: 0.8667\n",
      "\n",
      "Test Accuracy: 86.67%\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=2, batch_size=32,\n",
    "                    validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the test accuracy\n",
    "print(f\"\\nTest Accuracy: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating and training a new model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_file = \"/Users/nyzy/Library/CloudStorage/OneDrive-Personal/deep_learning/resnet_model.h5\"\n",
    "# Check if the model file exists. If it does, load it. If not, create, train, and save the model.\n",
    "if os.path.exists(model_file):\n",
    "    print(\"Loading existing model\")\n",
    "    model = load_model(model_file)\n",
    "else:\n",
    "    print(\"Creating and training a new model\")\n",
    "    \n",
    "    # Train the model with your data\n",
    "    # model.fit(x_train, y_train, epochs=..., batch_size=...)\n",
    "    history.save(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"/Users/nyzy/Library/CloudStorage/OneDrive-Personal/deep_learning/resnet_model.h5\"\n",
    "model.save(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75cbfe992e831883bebc34d351837a73fc44aae74ab7e2dffad989642b16aeb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
