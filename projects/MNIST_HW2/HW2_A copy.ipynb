{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-08 18:06:48.545497: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)\n",
    "import keras\n",
    "import warnings # to filter out warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data from keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data() \n",
    "\n",
    "X_train = X_train.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
    "X_test = X_test.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
    "\n",
    "#X_train= X_train.reshape(X_train.shape[0],X_train.shape[1]*X_train.shape[2])\n",
    "#X_test = X_test.reshape(X_test.shape[0],X_test.shape[1]*X_test.shape[2])\n",
    "#y_train = y_train.reshape(y_train.shape[0],1)\n",
    "#y_test = y_test.reshape(y_test.shape[0],1)\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 65s 34ms/step - loss: 0.6942 - accuracy: 0.7599 - val_loss: 0.3961 - val_accuracy: 0.8552\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 93s 50ms/step - loss: 0.4235 - accuracy: 0.8568 - val_loss: 0.3258 - val_accuracy: 0.8881\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 87s 46ms/step - loss: 0.3632 - accuracy: 0.8767 - val_loss: 0.4161 - val_accuracy: 0.8519\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 102s 54ms/step - loss: 0.3220 - accuracy: 0.8924 - val_loss: 0.3017 - val_accuracy: 0.8895\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 100s 53ms/step - loss: 0.2981 - accuracy: 0.8992 - val_loss: 0.2711 - val_accuracy: 0.9010\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 105s 56ms/step - loss: 0.2827 - accuracy: 0.9044 - val_loss: 0.2709 - val_accuracy: 0.9015\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 107s 57ms/step - loss: 0.2647 - accuracy: 0.9119 - val_loss: 0.2781 - val_accuracy: 0.8968\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 119s 63ms/step - loss: 0.2465 - accuracy: 0.9160 - val_loss: 0.2851 - val_accuracy: 0.8993\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 112s 60ms/step - loss: 0.2418 - accuracy: 0.9193 - val_loss: 0.2690 - val_accuracy: 0.9088\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 121s 65ms/step - loss: 0.2257 - accuracy: 0.9236 - val_loss: 0.2897 - val_accuracy: 0.9083\n",
      "313/313 [==============================] - 9s 30ms/step - loss: 0.2897 - accuracy: 0.9083\n",
      "\n",
      "Test Accuracy: 90.83%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models,layers\n",
    "#from tensorflow.keras.models import Sequential \n",
    "#from tensorflow.keras.models import Dense \n",
    "#from tensorflow.keras import regularizers\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "# Building the CNN model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), strides=(1, 1), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "\n",
    "for _ in range(2):\n",
    "    model.add(layers.Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='softmax'))  # Output layer\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=2, batch_size=32,\n",
    "                    validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the test accuracy\n",
    "print(f\"\\nTest Accuracy: {test_acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel = create_model()\\n# Train the model\\nhistory = model.fit(X_train, y_train, epochs=1, batch_size=32,\\n                    validation_data=(X_test, y_test))\\n\\n# Evaluate the model\\ntest_loss, test_acc = model.evaluate(X_test, y_test)\\n\\n# Print the test accuracy\\nprint(f\"\\nTest Accuracy: {test_acc * 100:.2f}%\")\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import models,layers\n",
    "#from tensorflow.keras.models import Sequential \n",
    "#from tensorflow.keras.models import Dense \n",
    "#from tensorflow.keras import regularizers\n",
    "tf.random.set_seed(1234)\n",
    "def create_model():\n",
    "    # Building the CNN model\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), strides=(1, 1), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "\n",
    "    for _ in range(4):\n",
    "        model.add(layers.Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(10, activation='softmax'))  # Output layer\n",
    "\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model()\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=1, batch_size=32,\n",
    "                    validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the test accuracy\n",
    "print(f\"\\nTest Accuracy: {test_acc * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 319s 212ms/step - loss: 1.3926 - accuracy: 0.4769\n",
      "375/375 [==============================] - 26s 69ms/step - loss: 0.9841 - accuracy: 0.5798\n",
      "1500/1500 [==============================] - 300s 199ms/step - loss: 1.6268 - accuracy: 0.3975\n",
      "375/375 [==============================] - 24s 63ms/step - loss: 1.0090 - accuracy: 0.5774\n",
      "1500/1500 [==============================] - 280s 185ms/step - loss: 1.4107 - accuracy: 0.5059\n",
      "375/375 [==============================] - 20s 54ms/step - loss: 0.6698 - accuracy: 0.7565\n",
      "1500/1500 [==============================] - 281s 186ms/step - loss: 1.4918 - accuracy: 0.4643\n",
      "375/375 [==============================] - 27s 70ms/step - loss: 0.8624 - accuracy: 0.6543\n",
      "1500/1500 [==============================] - 301s 199ms/step - loss: 1.3709 - accuracy: 0.5240\n",
      "375/375 [==============================] - 21s 55ms/step - loss: 0.6678 - accuracy: 0.7454\n",
      "Baseline Accuracy: 66.27% (+/- 7.73%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "# Wrap Keras model into scikit-learn model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=1, batch_size=32, verbose=1)\n",
    "\n",
    "# 5-Fold Cross validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "\n",
    "results = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(f\"Baseline Accuracy: {results.mean()*100:.2f}% (+/- {results.std()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Act: relu, Opt: adam, Batch: 16, LR: 0.001, Test Acc: 87.90%\n",
      "Act: relu, Opt: adam, Batch: 16, LR: 0.0001, Test Acc: 87.10%\n",
      "Act: relu, Opt: adam, Batch: 16, LR: 1e-05, Test Acc: 84.54%\n",
      "Act: relu, Opt: adam, Batch: 32, LR: 0.001, Test Acc: 86.19%\n",
      "Act: relu, Opt: adam, Batch: 32, LR: 0.0001, Test Acc: 85.66%\n",
      "Act: relu, Opt: adam, Batch: 32, LR: 1e-05, Test Acc: 81.77%\n",
      "Act: relu, Opt: adam, Batch: 64, LR: 0.001, Test Acc: 87.04%\n",
      "Act: relu, Opt: adam, Batch: 64, LR: 0.0001, Test Acc: 86.30%\n",
      "Act: relu, Opt: adam, Batch: 64, LR: 1e-05, Test Acc: 81.82%\n",
      "Act: relu, Opt: adagrad, Batch: 16, LR: 0.001, Test Acc: 86.49%\n",
      "Act: relu, Opt: adagrad, Batch: 16, LR: 0.0001, Test Acc: 79.53%\n",
      "Act: relu, Opt: adagrad, Batch: 16, LR: 1e-05, Test Acc: 53.61%\n",
      "Act: relu, Opt: adagrad, Batch: 32, LR: 0.001, Test Acc: 85.84%\n",
      "Act: relu, Opt: adagrad, Batch: 32, LR: 0.0001, Test Acc: 79.23%\n",
      "Act: relu, Opt: adagrad, Batch: 32, LR: 1e-05, Test Acc: 56.35%\n",
      "Act: relu, Opt: adagrad, Batch: 64, LR: 0.001, Test Acc: 85.71%\n",
      "Act: relu, Opt: adagrad, Batch: 64, LR: 0.0001, Test Acc: 78.88%\n",
      "Act: relu, Opt: adagrad, Batch: 64, LR: 1e-05, Test Acc: 50.98%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adam, Batch: 16, LR: 0.001, Test Acc: 87.22%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adam, Batch: 16, LR: 0.0001, Test Acc: 86.52%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adam, Batch: 16, LR: 1e-05, Test Acc: 85.15%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adam, Batch: 32, LR: 0.001, Test Acc: 86.83%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adam, Batch: 32, LR: 0.0001, Test Acc: 86.69%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adam, Batch: 32, LR: 1e-05, Test Acc: 83.98%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adam, Batch: 64, LR: 0.001, Test Acc: 85.66%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adam, Batch: 64, LR: 0.0001, Test Acc: 86.92%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adam, Batch: 64, LR: 1e-05, Test Acc: 82.61%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adagrad, Batch: 16, LR: 0.001, Test Acc: 86.75%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adagrad, Batch: 16, LR: 0.0001, Test Acc: 81.08%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adagrad, Batch: 16, LR: 1e-05, Test Acc: 61.45%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adagrad, Batch: 32, LR: 0.001, Test Acc: 85.40%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adagrad, Batch: 32, LR: 0.0001, Test Acc: 80.58%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adagrad, Batch: 32, LR: 1e-05, Test Acc: 63.04%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adagrad, Batch: 64, LR: 0.001, Test Acc: 85.74%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adagrad, Batch: 64, LR: 0.0001, Test Acc: 78.80%\n",
      "Act: <keras.layers.activation.leaky_relu.LeakyReLU object at 0x7fdcb0210220>, Opt: adagrad, Batch: 64, LR: 1e-05, Test Acc: 59.20%\n",
      "\n",
      "Best Parameters - Act: relu, Opt: adam, Batch: 16, LR: 0.001, Test Acc: 87.90%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam, Adagrad\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "import itertools\n",
    "\n",
    "# Define the grid search parameters\n",
    "activation_functions = ['relu', LeakyReLU()] \n",
    "optimizers = ['adam', 'adagrad']  \n",
    "batch_sizes = [16, 32, 64]  \n",
    "learning_rates = [0.001, 0.0001, 0.00001] \n",
    "\n",
    "# Placeholder to store the results\n",
    "grid_search_results = []\n",
    "\n",
    "# Loop through the parameter combinations\n",
    "for params in itertools.product(activation_functions, optimizers, batch_sizes, learning_rates):\n",
    "    act_func, opt, batch, lr = params\n",
    "    \n",
    "    # Creating the model\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), padding='same', input_shape=(28, 28, 1)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    if act_func == 'relu':\n",
    "        model.add(layers.Activation('relu'))\n",
    "    else:\n",
    "        model.add(LeakyReLU())\n",
    "    \n",
    "    for _ in range(4):\n",
    "        model.add(layers.Conv2D(64, (3, 3), padding='same'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        if act_func == 'relu':\n",
    "            model.add(layers.Activation('relu'))\n",
    "        else:\n",
    "            model.add(LeakyReLU())\n",
    "        \n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(64))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(10, activation='softmax'))  # Output layer\n",
    "\n",
    "    if opt == 'adam':\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "    else:\n",
    "        optimizer = Adagrad(learning_rate=lr)\n",
    "        \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=1, batch_size=batch, verbose=0)  \n",
    "\n",
    "    # Evaluate the model\n",
    "    _, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    \n",
    "    grid_search_results.append((act_func, opt, batch, lr, test_acc))\n",
    "    print(f\"Act: {act_func}, Opt: {opt}, Batch: {batch}, LR: {lr}, Test Acc: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Print the best result\n",
    "best_params = max(grid_search_results, key=lambda x: x[4])\n",
    "print(f\"\\nBest Parameters - Act: {best_params[0]}, Opt: {best_params[1]}, Batch: {best_params[2]}, LR: {best_params[3]}, Test Acc: {best_params[4]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 120s 63ms/step - loss: 1.2142 - accuracy: 0.5661 - val_loss: 0.5970 - val_accuracy: 0.7362\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 111s 59ms/step - loss: 0.8000 - accuracy: 0.6822 - val_loss: 0.5826 - val_accuracy: 0.7555\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 108s 57ms/step - loss: 0.7111 - accuracy: 0.7126 - val_loss: 0.5866 - val_accuracy: 0.7562\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 126s 67ms/step - loss: 0.6369 - accuracy: 0.7366 - val_loss: 0.5265 - val_accuracy: 0.7743\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 122s 65ms/step - loss: 0.6027 - accuracy: 0.7510 - val_loss: 0.5698 - val_accuracy: 0.7738\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 121s 64ms/step - loss: 0.5717 - accuracy: 0.7728 - val_loss: 0.4635 - val_accuracy: 0.8128\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 118s 63ms/step - loss: 0.5300 - accuracy: 0.7892 - val_loss: 0.4101 - val_accuracy: 0.8569\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 116s 62ms/step - loss: 0.4983 - accuracy: 0.8081 - val_loss: 0.4299 - val_accuracy: 0.8615\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 119s 64ms/step - loss: 0.4761 - accuracy: 0.8235 - val_loss: 0.3930 - val_accuracy: 0.8553\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 129s 69ms/step - loss: 0.4495 - accuracy: 0.8335 - val_loss: 0.4497 - val_accuracy: 0.8197\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.4497 - accuracy: 0.8197\n",
      "\n",
      "Test Accuracy after Data Augmentation: 81.97%\n"
     ]
    }
   ],
   "source": [
    "#Data Augumentation \n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create an instance of the ImageDataGenerator class\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,       # Rotate images up to 10 degrees\n",
    "    width_shift_range=0.1,   # Shift images horizontally\n",
    "    height_shift_range=0.1,  # Shift images vertically\n",
    "    shear_range=0.1,         # Shear transformation\n",
    "    zoom_range=0.1           # Zoom in on images\n",
    ")\n",
    "\n",
    "# Fit the data generator to your training data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Rebuilding your model from part (a)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), strides=(1, 1), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "for _ in range(4):\n",
    "    model.add(layers.Conv2D(64, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='softmax'))  # Output layer\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training the model using the augmented data generator\n",
    "# Note that steps_per_epoch should usually be total_samples / batch_size\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
    "                    steps_per_epoch=len(X_train) / 32, epochs=10,\n",
    "                    validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate and print test accuracy\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nTest Accuracy after Data Augmentation: {test_acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_2\n",
      "block1_conv1\n",
      "block1_conv2\n",
      "block1_pool\n",
      "block2_conv1\n",
      "block2_conv2\n",
      "block2_pool\n",
      "block3_conv1\n",
      "block3_conv2\n",
      "block3_conv3\n",
      "block3_conv4\n",
      "block3_pool\n",
      "block4_conv1\n",
      "block4_conv2\n",
      "block4_conv3\n",
      "block4_conv4\n",
      "block4_pool\n",
      "block5_conv1\n",
      "block5_conv2\n",
      "block5_conv3\n",
      "block5_conv4\n",
      "block5_pool\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 512)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 128)               65664     \n",
      "                                                                 \n",
      " dropout_89 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_135 (Dense)           (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,572,682\n",
      "Trainable params: 66,954\n",
      "Non-trainable params: 3,505,728\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "\n",
    "# Load the VGG19 model\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Print all layer names to identify where to truncate the model\n",
    "for layer in base_model.layers:\n",
    "    print(layer.name)\n",
    "\n",
    "# Truncate the model at 'block4_conv1'\n",
    "base_output = base_model.get_layer('block4_conv1').output\n",
    "\n",
    "# Add new layers on top\n",
    "x = GlobalAveragePooling2D()(base_output)  # Global Average Pooling layer\n",
    "x = Dense(128, activation='relu')(x)  # Fully connected layer with 128 neurons\n",
    "x = Dropout(0.5)(x)  # Dropout layer for regularization\n",
    "predictions = Dense(10, activation='softmax')(x)  # Output layer assuming 10 classes\n",
    "\n",
    "# Assemble the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze all layers in the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Print the model summary to check the architecture\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Now, the model is ready to be trained on your dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-12 22:21:00.137386: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-12 22:21:25.975821: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               65664     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,572,682\n",
      "Trainable params: 66,954\n",
      "Non-trainable params: 3,505,728\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "\n",
    "# Load the VGG19 model\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Truncate the model at 'block4_conv1'\n",
    "base_output = base_model.get_layer('block4_conv1').output\n",
    "\n",
    "# Add new layers on top\n",
    "x = GlobalAveragePooling2D()(base_output)  # Global Average Pooling layer\n",
    "x = Dense(128, activation='relu')(x)  # Fully connected layer with 128 neurons\n",
    "x = Dropout(0.5)(x)  # Dropout layer for regularization\n",
    "predictions = Dense(10, activation='softmax')(x)  # Output layer assuming 10 classes\n",
    "\n",
    "# Assemble the final model\n",
    "final_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze all layers in the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Print the model summary to check the architecture\n",
    "final_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_296 (Conv2D)            (None, 28, 28, 32)   320         ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_296 (Batch  (None, 28, 28, 32)  128         ['conv2d_296[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_43 (ReLU)                (None, 28, 28, 32)   0           ['batch_normalization_296[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_297 (Conv2D)            (None, 28, 28, 32)   9248        ['re_lu_43[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_297 (Batch  (None, 28, 28, 32)  128         ['conv2d_297[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_44 (ReLU)                (None, 28, 28, 32)   0           ['batch_normalization_297[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_298 (Conv2D)            (None, 28, 28, 32)   9248        ['re_lu_44[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_298 (Batch  (None, 28, 28, 32)  128         ['conv2d_298[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 28, 28, 32)   0           ['batch_normalization_298[0][0]',\n",
      "                                                                  're_lu_43[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_45 (ReLU)                (None, 28, 28, 32)   0           ['add_21[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_299 (Conv2D)            (None, 28, 28, 32)   9248        ['re_lu_45[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_299 (Batch  (None, 28, 28, 32)  128         ['conv2d_299[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_46 (ReLU)                (None, 28, 28, 32)   0           ['batch_normalization_299[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_300 (Conv2D)            (None, 28, 28, 32)   9248        ['re_lu_46[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_300 (Batch  (None, 28, 28, 32)  128         ['conv2d_300[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_22 (Add)                   (None, 28, 28, 32)   0           ['batch_normalization_300[0][0]',\n",
      "                                                                  're_lu_45[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_47 (ReLU)                (None, 28, 28, 32)   0           ['add_22[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_301 (Conv2D)            (None, 28, 28, 32)   9248        ['re_lu_47[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_301 (Batch  (None, 28, 28, 32)  128         ['conv2d_301[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_48 (ReLU)                (None, 28, 28, 32)   0           ['batch_normalization_301[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_302 (Conv2D)            (None, 28, 28, 32)   9248        ['re_lu_48[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_302 (Batch  (None, 28, 28, 32)  128         ['conv2d_302[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, 28, 28, 32)   0           ['batch_normalization_302[0][0]',\n",
      "                                                                  're_lu_47[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_49 (ReLU)                (None, 28, 28, 32)   0           ['add_23[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_303 (Conv2D)            (None, 28, 28, 64)   18496       ['re_lu_49[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_303 (Batch  (None, 28, 28, 64)  256         ['conv2d_303[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_50 (ReLU)                (None, 28, 28, 64)   0           ['batch_normalization_303[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_304 (Conv2D)            (None, 28, 28, 64)   36928       ['re_lu_50[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_305 (Conv2D)            (None, 28, 28, 64)   2112        ['re_lu_49[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_304 (Batch  (None, 28, 28, 64)  256         ['conv2d_304[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_305 (Batch  (None, 28, 28, 64)  256         ['conv2d_305[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_24 (Add)                   (None, 28, 28, 64)   0           ['batch_normalization_304[0][0]',\n",
      "                                                                  'batch_normalization_305[0][0]']\n",
      "                                                                                                  \n",
      " re_lu_51 (ReLU)                (None, 28, 28, 64)   0           ['add_24[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_306 (Conv2D)            (None, 28, 28, 64)   36928       ['re_lu_51[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_306 (Batch  (None, 28, 28, 64)  256         ['conv2d_306[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_52 (ReLU)                (None, 28, 28, 64)   0           ['batch_normalization_306[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_307 (Conv2D)            (None, 28, 28, 64)   36928       ['re_lu_52[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_307 (Batch  (None, 28, 28, 64)  256         ['conv2d_307[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_25 (Add)                   (None, 28, 28, 64)   0           ['batch_normalization_307[0][0]',\n",
      "                                                                  're_lu_51[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_53 (ReLU)                (None, 28, 28, 64)   0           ['add_25[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_308 (Conv2D)            (None, 28, 28, 64)   36928       ['re_lu_53[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_308 (Batch  (None, 28, 28, 64)  256         ['conv2d_308[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_54 (ReLU)                (None, 28, 28, 64)   0           ['batch_normalization_308[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_309 (Conv2D)            (None, 28, 28, 64)   36928       ['re_lu_54[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_309 (Batch  (None, 28, 28, 64)  256         ['conv2d_309[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_26 (Add)                   (None, 28, 28, 64)   0           ['batch_normalization_309[0][0]',\n",
      "                                                                  're_lu_53[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_55 (ReLU)                (None, 28, 28, 64)   0           ['add_26[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_310 (Conv2D)            (None, 28, 28, 128)  73856       ['re_lu_55[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_310 (Batch  (None, 28, 28, 128)  512        ['conv2d_310[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_56 (ReLU)                (None, 28, 28, 128)  0           ['batch_normalization_310[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_311 (Conv2D)            (None, 28, 28, 128)  147584      ['re_lu_56[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_312 (Conv2D)            (None, 28, 28, 128)  8320        ['re_lu_55[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_311 (Batch  (None, 28, 28, 128)  512        ['conv2d_311[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_312 (Batch  (None, 28, 28, 128)  512        ['conv2d_312[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_27 (Add)                   (None, 28, 28, 128)  0           ['batch_normalization_311[0][0]',\n",
      "                                                                  'batch_normalization_312[0][0]']\n",
      "                                                                                                  \n",
      " re_lu_57 (ReLU)                (None, 28, 28, 128)  0           ['add_27[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_313 (Conv2D)            (None, 28, 28, 128)  147584      ['re_lu_57[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_313 (Batch  (None, 28, 28, 128)  512        ['conv2d_313[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_58 (ReLU)                (None, 28, 28, 128)  0           ['batch_normalization_313[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_314 (Conv2D)            (None, 28, 28, 128)  147584      ['re_lu_58[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_314 (Batch  (None, 28, 28, 128)  512        ['conv2d_314[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_28 (Add)                   (None, 28, 28, 128)  0           ['batch_normalization_314[0][0]',\n",
      "                                                                  're_lu_57[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_59 (ReLU)                (None, 28, 28, 128)  0           ['add_28[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_315 (Conv2D)            (None, 28, 28, 128)  147584      ['re_lu_59[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_315 (Batch  (None, 28, 28, 128)  512        ['conv2d_315[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_60 (ReLU)                (None, 28, 28, 128)  0           ['batch_normalization_315[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_316 (Conv2D)            (None, 28, 28, 128)  147584      ['re_lu_60[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_316 (Batch  (None, 28, 28, 128)  512        ['conv2d_316[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_29 (Add)                   (None, 28, 28, 128)  0           ['batch_normalization_316[0][0]',\n",
      "                                                                  're_lu_59[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_61 (ReLU)                (None, 28, 28, 128)  0           ['add_29[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_5 (Gl  (None, 128)         0           ['re_lu_61[0][0]']               \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " flatten_45 (Flatten)           (None, 128)          0           ['global_average_pooling2d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_142 (Dense)              (None, 128)          16512       ['flatten_45[0][0]']             \n",
      "                                                                                                  \n",
      " dense_143 (Dense)              (None, 10)           1290        ['dense_142[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,105,226\n",
      "Trainable params: 1,102,090\n",
      "Non-trainable params: 3,136\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, Add, GlobalAveragePooling2D, Dense, Flatten\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "\n",
    "# Function to create a residual block\n",
    "def residual_block(x, filters):\n",
    "    shortcut = x\n",
    "    \n",
    "    # Main path\n",
    "    x = Conv2D(filters, (3,3), strides=(1,1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(filters, (3,3), strides=(1,1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # If the number of filters does not match, apply a 1x1 conv to the shortcut path\n",
    "    if shortcut.shape[-1] != filters:\n",
    "        shortcut = Conv2D(filters, (1,1), strides=(1,1), padding='same')(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)  # Optional: add BatchNormalization here as well\n",
    "    \n",
    "    # Adding the shortcut to the output\n",
    "    x = Add()([x, shortcut])\n",
    "    x = ReLU()(x)\n",
    "    return x\n",
    "\n",
    "# Function to create the ResNet model\n",
    "def create_resnet_model():\n",
    "    inputs = Input(shape=(28, 28, 1))  # Adjust the input shape according to your data\n",
    "    x = Conv2D(32, (3,3), strides=(1,1), padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "    # Section A\n",
    "    for _ in range(3):\n",
    "        x = residual_block(x, 32)\n",
    "    \n",
    "    # Section B\n",
    "    for _ in range(3):\n",
    "        x = residual_block(x, 64)\n",
    "    \n",
    "    # Section C\n",
    "    for _ in range(3):\n",
    "        x = residual_block(x, 128)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)  # Adjust the size and activation function according to your needs\n",
    "    outputs = Dense(10, activation='softmax')(x)  # Assuming 10 classes for classification\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "'''\n",
    "model_file = 'resnet_model.h5'\n",
    "\n",
    "# Check if the model file exists. If it does, load it. If not, create, train, and save the model.\n",
    "if os.path.exists(model_file):\n",
    "    print(\"Loading existing model\")\n",
    "    model = load_model(model_file)\n",
    "else:\n",
    "    print(\"Creating and training a new model\")\n",
    "    model = create_resnet_model()\n",
    "    # Train the model with your data\n",
    "    # model.fit(x_train, y_train, epochs=..., batch_size=...)\n",
    "    model.save(model_file)\n",
    "'''\n",
    "model = create_resnet_model()\n",
    "# Print model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_296 (Conv2D)            (None, 28, 28, 32)   320         ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_296 (Batch  (None, 28, 28, 32)  128         ['conv2d_296[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_43 (ReLU)                (None, 28, 28, 32)   0           ['batch_normalization_296[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_297 (Conv2D)            (None, 28, 28, 32)   9248        ['re_lu_43[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_297 (Batch  (None, 28, 28, 32)  128         ['conv2d_297[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_44 (ReLU)                (None, 28, 28, 32)   0           ['batch_normalization_297[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_298 (Conv2D)            (None, 28, 28, 32)   9248        ['re_lu_44[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_298 (Batch  (None, 28, 28, 32)  128         ['conv2d_298[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 28, 28, 32)   0           ['batch_normalization_298[0][0]',\n",
      "                                                                  're_lu_43[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_45 (ReLU)                (None, 28, 28, 32)   0           ['add_21[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_299 (Conv2D)            (None, 28, 28, 32)   9248        ['re_lu_45[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_299 (Batch  (None, 28, 28, 32)  128         ['conv2d_299[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_46 (ReLU)                (None, 28, 28, 32)   0           ['batch_normalization_299[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_300 (Conv2D)            (None, 28, 28, 32)   9248        ['re_lu_46[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_300 (Batch  (None, 28, 28, 32)  128         ['conv2d_300[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_22 (Add)                   (None, 28, 28, 32)   0           ['batch_normalization_300[0][0]',\n",
      "                                                                  're_lu_45[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_47 (ReLU)                (None, 28, 28, 32)   0           ['add_22[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_301 (Conv2D)            (None, 28, 28, 32)   9248        ['re_lu_47[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_301 (Batch  (None, 28, 28, 32)  128         ['conv2d_301[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_48 (ReLU)                (None, 28, 28, 32)   0           ['batch_normalization_301[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_302 (Conv2D)            (None, 28, 28, 32)   9248        ['re_lu_48[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_302 (Batch  (None, 28, 28, 32)  128         ['conv2d_302[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, 28, 28, 32)   0           ['batch_normalization_302[0][0]',\n",
      "                                                                  're_lu_47[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_49 (ReLU)                (None, 28, 28, 32)   0           ['add_23[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_303 (Conv2D)            (None, 28, 28, 64)   18496       ['re_lu_49[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_303 (Batch  (None, 28, 28, 64)  256         ['conv2d_303[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_50 (ReLU)                (None, 28, 28, 64)   0           ['batch_normalization_303[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_304 (Conv2D)            (None, 28, 28, 64)   36928       ['re_lu_50[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_305 (Conv2D)            (None, 28, 28, 64)   2112        ['re_lu_49[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_304 (Batch  (None, 28, 28, 64)  256         ['conv2d_304[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_305 (Batch  (None, 28, 28, 64)  256         ['conv2d_305[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_24 (Add)                   (None, 28, 28, 64)   0           ['batch_normalization_304[0][0]',\n",
      "                                                                  'batch_normalization_305[0][0]']\n",
      "                                                                                                  \n",
      " re_lu_51 (ReLU)                (None, 28, 28, 64)   0           ['add_24[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_306 (Conv2D)            (None, 28, 28, 64)   36928       ['re_lu_51[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_306 (Batch  (None, 28, 28, 64)  256         ['conv2d_306[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_52 (ReLU)                (None, 28, 28, 64)   0           ['batch_normalization_306[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_307 (Conv2D)            (None, 28, 28, 64)   36928       ['re_lu_52[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_307 (Batch  (None, 28, 28, 64)  256         ['conv2d_307[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_25 (Add)                   (None, 28, 28, 64)   0           ['batch_normalization_307[0][0]',\n",
      "                                                                  're_lu_51[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_53 (ReLU)                (None, 28, 28, 64)   0           ['add_25[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_308 (Conv2D)            (None, 28, 28, 64)   36928       ['re_lu_53[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_308 (Batch  (None, 28, 28, 64)  256         ['conv2d_308[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_54 (ReLU)                (None, 28, 28, 64)   0           ['batch_normalization_308[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_309 (Conv2D)            (None, 28, 28, 64)   36928       ['re_lu_54[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_309 (Batch  (None, 28, 28, 64)  256         ['conv2d_309[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_26 (Add)                   (None, 28, 28, 64)   0           ['batch_normalization_309[0][0]',\n",
      "                                                                  're_lu_53[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_55 (ReLU)                (None, 28, 28, 64)   0           ['add_26[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_310 (Conv2D)            (None, 28, 28, 128)  73856       ['re_lu_55[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_310 (Batch  (None, 28, 28, 128)  512        ['conv2d_310[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_56 (ReLU)                (None, 28, 28, 128)  0           ['batch_normalization_310[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_311 (Conv2D)            (None, 28, 28, 128)  147584      ['re_lu_56[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_312 (Conv2D)            (None, 28, 28, 128)  8320        ['re_lu_55[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_311 (Batch  (None, 28, 28, 128)  512        ['conv2d_311[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_312 (Batch  (None, 28, 28, 128)  512        ['conv2d_312[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_27 (Add)                   (None, 28, 28, 128)  0           ['batch_normalization_311[0][0]',\n",
      "                                                                  'batch_normalization_312[0][0]']\n",
      "                                                                                                  \n",
      " re_lu_57 (ReLU)                (None, 28, 28, 128)  0           ['add_27[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_313 (Conv2D)            (None, 28, 28, 128)  147584      ['re_lu_57[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_313 (Batch  (None, 28, 28, 128)  512        ['conv2d_313[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_58 (ReLU)                (None, 28, 28, 128)  0           ['batch_normalization_313[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_314 (Conv2D)            (None, 28, 28, 128)  147584      ['re_lu_58[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_314 (Batch  (None, 28, 28, 128)  512        ['conv2d_314[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_28 (Add)                   (None, 28, 28, 128)  0           ['batch_normalization_314[0][0]',\n",
      "                                                                  're_lu_57[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_59 (ReLU)                (None, 28, 28, 128)  0           ['add_28[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_315 (Conv2D)            (None, 28, 28, 128)  147584      ['re_lu_59[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_315 (Batch  (None, 28, 28, 128)  512        ['conv2d_315[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu_60 (ReLU)                (None, 28, 28, 128)  0           ['batch_normalization_315[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_316 (Conv2D)            (None, 28, 28, 128)  147584      ['re_lu_60[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_316 (Batch  (None, 28, 28, 128)  512        ['conv2d_316[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_29 (Add)                   (None, 28, 28, 128)  0           ['batch_normalization_316[0][0]',\n",
      "                                                                  're_lu_59[0][0]']               \n",
      "                                                                                                  \n",
      " re_lu_61 (ReLU)                (None, 28, 28, 128)  0           ['add_29[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_5 (Gl  (None, 128)         0           ['re_lu_61[0][0]']               \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " flatten_45 (Flatten)           (None, 128)          0           ['global_average_pooling2d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_142 (Dense)              (None, 128)          16512       ['flatten_45[0][0]']             \n",
      "                                                                                                  \n",
      " dense_143 (Dense)              (None, 10)           1290        ['dense_142[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,105,226\n",
      "Trainable params: 1,102,090\n",
      "Non-trainable params: 3,136\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1875/1875 [==============================] - 1635s 872ms/step - loss: 0.4822 - accuracy: 0.8249 - val_loss: 0.6646 - val_accuracy: 0.7855\n",
      "Epoch 2/2\n",
      "1875/1875 [==============================] - 1708s 911ms/step - loss: 0.3222 - accuracy: 0.8844 - val_loss: 0.4575 - val_accuracy: 0.8475\n",
      "313/313 [==============================] - 70s 224ms/step - loss: 0.4575 - accuracy: 0.8475\n",
      "\n",
      "Test Accuracy: 84.75%\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=2, batch_size=32,\n",
    "                    validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the test accuracy\n",
    "print(f\"\\nTest Accuracy: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75cbfe992e831883bebc34d351837a73fc44aae74ab7e2dffad989642b16aeb2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
